{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wound-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finite-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "major-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.weights = (np.random.rand(input_dim, output_dim) - 0.5) * 0.01\n",
    "        self.bias = np.random.rand(1, output_dim) - 0.5\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        self.input = x\n",
    "        self.output = np.dot(x, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, next_layer_grads, lr):\n",
    "        grads = np.dot(next_layer_grads, self.weights.T)\n",
    "        dW = np.dot(self.input.T, next_layer_grads)\n",
    "        db = np.sum(next_layer_grads, axis=0)\n",
    "        \n",
    "        self.weights -= lr * dW\n",
    "        self.bias -= lr * db\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "characteristic-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation):\n",
    "        self.activation = activation\n",
    "        if (activation == 'tanh'):\n",
    "            self.__forward_prop_fn__ = self.__tanh__\n",
    "            self.__backward_prop_fn__ = self.__dtanh__\n",
    "        elif (activation == 'sigmoid'):\n",
    "            self.__forward_prop_fn__ = self.__sigmoid__\n",
    "            self.__backward_prop_fn__ = self.__dsigmoid__\n",
    "        elif (activation == 'relu'):\n",
    "            self.__forward_prop_fn__ = self.__relu__\n",
    "            self.__backward_prop_fn__ = self.__drelu__\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        self.input = x\n",
    "        self.output = self.__forward_prop_fn__(x)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, next_layer_grads, learning_rate):\n",
    "        return self.__backward_prop_fn__(self.input) * next_layer_grads\n",
    "    \n",
    "    def __tanh__(self, z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    def __dtanh__(self, z):\n",
    "        return 1-np.tanh(z)**2\n",
    "\n",
    "    def __sigmoid__(self, z):\n",
    "        return (1 / (1 + np.exp(-z) + 10e-8))\n",
    "\n",
    "    def __dsigmoid__(self, z):\n",
    "        s = self.__sigmoid__(z)\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def __relu__(self, z):\n",
    "        return np.maximum(z, 0)\n",
    "    \n",
    "    def __drelu__(self, z):\n",
    "        dz = np.ones(z.shape)\n",
    "        dz[self.input <= 0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worth-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, loss):\n",
    "        self.loss = loss\n",
    "        if (loss == 'binary_crossentropy'):\n",
    "            self.forward_prop_fn = self.__binary_crossentropy__\n",
    "            self.backward_prop_fn = self.__dbinary_crossentropy__\n",
    "        elif (loss == 'mse'):\n",
    "            self.forward_prop_fn = self.__mse__\n",
    "            self.backward_prop_fn = self.__dmse__\n",
    "            \n",
    "    def __mse__(self, y_true, y_pred):\n",
    "        return np.mean(np.power(y_true-y_pred, 2))\n",
    "\n",
    "    def __dmse__(self, y_true, y_pred):\n",
    "        return 2*(y_pred-y_true)/y_true.size\n",
    "    \n",
    "    def __binary_crossentropy__(self, y_true, y_pred):\n",
    "        return -(1 / len(y_true)) * ((y_true * np.log(y_pred)) + ((1 - y_true) * np.log(1 - y_pred)))\n",
    "\n",
    "    def __dbinary_crossentropy__(self, y_true, y_pred):\n",
    "        return -(np.divide(y_true, y_pred) - np.divide(1 - y_true, 1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "filled-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, loss):\n",
    "        self.layers = []\n",
    "        self.loss = Loss(loss)\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def predict(self, input_data, batch_size=32):\n",
    "        m = len(input_data)\n",
    "        results = []\n",
    "        for batch in range(0, m, batch_size):\n",
    "            preds = input_data[batch:batch+batch_size]\n",
    "            for layer in self.layers:\n",
    "                preds = layer.forward_propagation(preds)\n",
    "            results.append(preds)\n",
    "        return np.array(results)\n",
    "\n",
    "    def fit(self, X, y, epochs, lr, batch_size=32):\n",
    "        m = len(X)\n",
    "\n",
    "        for i in tqdm(range(epochs)):\n",
    "            err = 0\n",
    "            for batch in range(0, m, batch_size):\n",
    "                preds = X[batch:batch+batch_size]\n",
    "                for layer in self.layers:\n",
    "                    preds = layer.forward_propagation(preds)\n",
    "\n",
    "                err += self.loss.forward_prop_fn(y[batch:batch+batch_size], preds)\n",
    "\n",
    "                error = self.loss.backward_prop_fn(y[batch:batch+batch_size], preds)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, lr)\n",
    "\n",
    "            err /= m\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smooth-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514a8790622040f3b52efd4df4768f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30   error=0.002807\n",
      "epoch 2/30   error=0.002611\n",
      "epoch 3/30   error=0.002350\n",
      "epoch 4/30   error=0.002045\n",
      "epoch 5/30   error=0.001641\n",
      "epoch 6/30   error=0.001364\n",
      "epoch 7/30   error=0.001177\n",
      "epoch 8/30   error=0.000951\n",
      "epoch 9/30   error=0.000796\n",
      "epoch 10/30   error=0.000706\n",
      "epoch 11/30   error=0.000642\n",
      "epoch 12/30   error=0.000593\n",
      "epoch 13/30   error=0.000556\n",
      "epoch 14/30   error=0.000526\n",
      "epoch 15/30   error=0.000500\n",
      "epoch 16/30   error=0.000478\n",
      "epoch 17/30   error=0.000458\n",
      "epoch 18/30   error=0.000439\n",
      "epoch 19/30   error=0.000423\n",
      "epoch 20/30   error=0.000407\n",
      "epoch 21/30   error=0.000393\n",
      "epoch 22/30   error=0.000380\n",
      "epoch 23/30   error=0.000368\n",
      "epoch 24/30   error=0.000357\n",
      "epoch 25/30   error=0.000347\n",
      "epoch 26/30   error=0.000338\n",
      "epoch 27/30   error=0.000329\n",
      "epoch 28/30   error=0.000321\n",
      "epoch 29/30   error=0.000314\n",
      "epoch 30/30   error=0.000307\n",
      "\n",
      "predicted values : \n",
      "[[[ 3.55788555e-03  3.84869627e-03 -4.63767997e-02 -2.77789265e-02\n",
      "   -1.59241049e-02  7.91942588e-03  1.42106149e-02  9.50535610e-01\n",
      "    1.70552732e-02 -3.27344137e-04]\n",
      "  [-8.48891496e-02  2.53127140e-02  9.13841568e-01  1.16772859e-01\n",
      "   -6.81799895e-03 -6.02214753e-02  3.54821703e-02  1.16226100e-02\n",
      "   -1.06298763e-01 -7.18657899e-03]\n",
      "  [-4.52372334e-03  9.61521924e-01 -2.41889011e-02 -2.33621978e-02\n",
      "   -1.63263625e-03 -9.19740350e-03  3.17881106e-02 -2.41339433e-02\n",
      "   -4.08425099e-02 -7.69012095e-03]]]\n",
      "true values : \n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Network\n",
    "net = Model('mse')\n",
    "net.add(Dense(28*28, 100))\n",
    "net.add(Activation('tanh'))\n",
    "net.add(Dense(100, 50))\n",
    "net.add(Activation('tanh'))\n",
    "net.add(Dense(50, 10))\n",
    "net.add(Activation('tanh'))\n",
    "\n",
    "\n",
    "net.fit(x_train, y_train, epochs=30, lr=0.1)\n",
    "\n",
    "out = net.predict(x_test[0:3])\n",
    "print(\"\\npredicted values : \")\n",
    "print(out)\n",
    "print(\"true values : \")\n",
    "print(y_test[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-evanescence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
