{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specific-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intermediate-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.weights = (np.random.rand(input_dim, output_dim) - 0.5) * 0.01\n",
    "        self.bias = np.random.rand(1, output_dim) - 0.5\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        self.input = x\n",
    "        self.output = np.dot(x, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, next_layer_grads, lr):\n",
    "        grads = np.dot(next_layer_grads, self.weights.T)\n",
    "        dW = np.dot(self.input.T, next_layer_grads)\n",
    "        db = np.sum(next_layer_grads, axis=0)\n",
    "        \n",
    "        self.weights -= lr * dW\n",
    "        self.bias -= lr * db\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smart-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation):\n",
    "        self.activation = activation\n",
    "        if (activation == 'tanh'):\n",
    "            self.__forward_prop_fn = self.__tanh\n",
    "            self.__backward_prop_fn = self.__dtanh\n",
    "        elif (activation == 'sigmoid'):\n",
    "            self.__forward_prop_fn = self.__sigmoid\n",
    "            self.__backward_prop_fn = self.__dsigmoid\n",
    "        elif (activation == 'relu'):\n",
    "            self.__forward_prop_fn = self.__relu\n",
    "            self.__backward_prop_fn = self.__drelu\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        self.input = x\n",
    "        self.output = self.__forward_prop_fn(x)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, next_layer_grads, learning_rate):\n",
    "        return self.__backward_prop_fn(self.input) * next_layer_grads\n",
    "    \n",
    "    def __tanh(self, z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    def __dtanh(self, z):\n",
    "        return 1-np.tanh(z)**2\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        return (1 / (1 + np.exp(-z) + 10e-8))\n",
    "\n",
    "    def __dsigmoid(self, z):\n",
    "        s = self.__sigmoid(z)\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def __relu(self, z):\n",
    "        return np.maximum(z, 0)\n",
    "    \n",
    "    def __drelu(self, z):\n",
    "        dz = np.ones(z.shape)\n",
    "        dz[self.input <= 0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beginning-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, loss):\n",
    "        self.loss = loss\n",
    "        if (loss == 'binary_crossentropy'):\n",
    "            self.forward_prop_fn = self.__binary_crossentropy\n",
    "            self.backward_prop_fn = self.__dbinary_crossentropy\n",
    "        elif (loss == 'mse'):\n",
    "            self.forward_prop_fn = self.__mse\n",
    "            self.backward_prop_fn = self.__dmse\n",
    "            \n",
    "    def __mse(self, y_true, y_pred):\n",
    "        return np.mean(np.power(y_true-y_pred, 2))\n",
    "\n",
    "    def __dmse(self, y_true, y_pred):\n",
    "        return 2*(y_pred-y_true)/y_true.size\n",
    "    \n",
    "    def __binary_crossentropy(self, y_true, y_pred):\n",
    "        return -(1 / len(y_true)) * ((y_true * np.log(y_pred)) + ((1 - y_true) * np.log(1 - y_pred)))\n",
    "\n",
    "    def __dbinary_crossentropy(self, y_true, y_pred):\n",
    "        return -(np.divide(y_true, y_pred) - np.divide(1 - y_true, 1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, loss):\n",
    "        self.layers = []\n",
    "        self.loss = Loss(loss)\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def predict(self, input_data, batch_size=32):\n",
    "        m = len(input_data)\n",
    "        results = []\n",
    "        for batch in range(0, m, batch_size):\n",
    "            preds = input_data[batch:batch+batch_size]\n",
    "            for layer in self.layers:\n",
    "                preds = layer.forward_propagation(preds)\n",
    "            results.append(preds)\n",
    "        return np.array(results)\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, X, y, epochs, lr, batch_size=32):\n",
    "        m = len(X)\n",
    "\n",
    "        for i in tqdm(range(epochs)):\n",
    "            err = 0\n",
    "            for batch in range(0, m, batch_size):\n",
    "                preds = X[batch:batch+batch_size]\n",
    "                for layer in self.layers:\n",
    "                    preds = layer.forward_propagation(preds)\n",
    "\n",
    "                err += self.loss.forward_prop_fn(y[batch:batch+batch_size], preds)\n",
    "\n",
    "                error = self.loss.backward_prop_fn(y[batch:batch+batch_size], preds)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, lr)\n",
    "\n",
    "            err /= m\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polyphonic-annual",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2f37afa4ae4589a4d416e68aaf99f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30   error=0.002800\n",
      "epoch 2/30   error=0.002611\n",
      "epoch 3/30   error=0.002375\n",
      "epoch 4/30   error=0.001985\n",
      "epoch 5/30   error=0.001578\n",
      "epoch 6/30   error=0.001304\n",
      "epoch 7/30   error=0.001082\n",
      "epoch 8/30   error=0.000901\n",
      "epoch 9/30   error=0.000773\n",
      "epoch 10/30   error=0.000688\n",
      "epoch 11/30   error=0.000635\n",
      "epoch 12/30   error=0.000595\n",
      "epoch 13/30   error=0.000562\n",
      "epoch 14/30   error=0.000534\n",
      "epoch 15/30   error=0.000510\n",
      "epoch 16/30   error=0.000489\n",
      "epoch 17/30   error=0.000471\n",
      "epoch 18/30   error=0.000454\n",
      "epoch 19/30   error=0.000440\n",
      "epoch 20/30   error=0.000426\n",
      "epoch 21/30   error=0.000414\n",
      "epoch 22/30   error=0.000403\n",
      "epoch 23/30   error=0.000392\n",
      "epoch 24/30   error=0.000382\n",
      "epoch 25/30   error=0.000373\n",
      "epoch 26/30   error=0.000365\n",
      "epoch 27/30   error=0.000357\n",
      "epoch 28/30   error=0.000349\n",
      "epoch 29/30   error=0.000342\n",
      "epoch 30/30   error=0.000335\n",
      "\n",
      "predicted values : \n",
      "[[[-0.00580485 -0.00544254 -0.00998993 -0.01517785 -0.00961837\n",
      "    0.02336946  0.00455222  0.94047022  0.02182044  0.02504781]\n",
      "  [-0.01641021  0.04197492  0.94119356  0.1120486  -0.01562909\n",
      "   -0.0354829  -0.0449366   0.00866798 -0.10600415 -0.02028023]\n",
      "  [-0.01351788  0.95206302 -0.01819281 -0.0207088  -0.01243647\n",
      "    0.01905991  0.04389243 -0.01701823 -0.0213493  -0.017763  ]]]\n",
      "true values : \n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Network\n",
    "net = NeuralNetwork('mse')\n",
    "net.add(Dense(28*28, 100))\n",
    "net.add(Activation('tanh'))\n",
    "net.add(Dense(100, 50))\n",
    "net.add(Activation('tanh'))\n",
    "net.add(Dense(50, 10))\n",
    "net.add(Activation('tanh'))\n",
    "\n",
    "\n",
    "net.fit(x_train, y_train, epochs=30, lr=0.1)\n",
    "\n",
    "out = net.predict(x_test[0:3])\n",
    "print(\"\\npredicted values : \")\n",
    "print(out)\n",
    "print(\"true values : \")\n",
    "print(y_test[0:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
